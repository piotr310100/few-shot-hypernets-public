{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from argparse import Namespace\n",
    "from regressionFlow.models.networks_regression_SDD import HyperRegression\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "flow_args = Namespace(model_type='PointNet', logprob_type='Laplace', input_dim=1, dims='3-4-2',\n",
    "                                   latent_dims='256', hyper_dims='128-32', num_blocks=1, latent_num_blocks=1,\n",
    "                                   layer_type='concatsquash', time_length=0.5, train_T=True, nonlinearity='tanh',\n",
    "                                   use_adjoint=True, solver='dopri5', atol=1e-05, rtol=1e-05, batch_norm=True,\n",
    "                                   sync_bn=False, bn_lag=0, root_dir=None, use_latent_flow=False,\n",
    "                                   use_deterministic_encoder=False,\n",
    "                                   zdim=1, optimizer='adam', batch_size=1000, lr=0.001, beta1=0.9,\n",
    "                                   beta2=0.999, momentum=0.9, weight_decay=1e-05, epochs=1000, seed=694754,\n",
    "                                   recon_weight=1.0, prior_weight=1.0, entropy_weight=1.0, scheduler='linear',\n",
    "                                   exp_decay=1.0, exp_decay_freq=1, image_size='28x28', data_dir='data/SDD/',\n",
    "                                   dataset_type='shapenet15k', cates=['airplane'],\n",
    "                                   mn40_data_dir='data/ModelNet40.PC15k',\n",
    "                                   mn10_data_dir='data/ModelNet10.PC15k', dataset_scale=1.0, random_rotate=False,\n",
    "                                   normalize_per_shape=False, normalize_std_per_axis=False, tr_max_sample_points=2048,\n",
    "                                   te_max_sample_points=2048, num_workers=4, use_all_data=False,\n",
    "                                   log_name='experiment_regression_flow_toy', viz_freq=1, val_freq=10, log_freq=1,\n",
    "                                   save_freq=5, no_validation=False, save_val_results=False, eval_classification=False,\n",
    "                                   no_eval_sampling=False, max_validate_shapes=None, resume_checkpoint=None,\n",
    "                                   resume_optimizer=False, resume_non_strict=False, resume_dataset_mean=None,\n",
    "                                   resume_dataset_std=None, world_size=1, dist_url='tcp://127.0.0.1:9991',\n",
    "                                   dist_backend='nccl', distributed=False, rank=0, gpu=0, evaluate_recon=False,\n",
    "                                   num_sample_shapes=10, num_sample_points=2048, use_sphere_dist=False,\n",
    "                                   use_div_approx_train=False, use_div_approx_test=False)\n",
    "\n",
    "\n",
    "def _get_opt_(params):\n",
    "    if flow_args.optimizer == 'adam':\n",
    "        optimizer = torch.optim.Adam(params, lr=flow_args.lr, betas=(flow_args.beta1, flow_args.beta2),\n",
    "                               weight_decay=flow_args.weight_decay)\n",
    "    elif flow_args.optimizer == 'sgd':\n",
    "        optimizer = torch.optim.SGD(params, lr=flow_args.lr, momentum=flow_args.momentum)\n",
    "    else:\n",
    "        assert 0, \"args.optimizer should be either 'adam' or 'sgd'\"\n",
    "    return optimizer\n",
    "\n",
    "def plotTheta(theta,loss):\n",
    "    X = theta.cpu().detach().numpy().reshape(65,5)\n",
    "    \n",
    "    pca = PCA(n_components=2)\n",
    "    X_r = pca.fit(X).transform(X)\n",
    "\n",
    "    plt.plot(X_r[:,0],X_r[:,1],\".\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "flow = HyperRegression(flow_args)\n",
    "opt = _get_opt_(list(flow.hyper.parameters()) + list(flow.point_cnf.parameters()))\n",
    "\n",
    "import torch\n",
    "from regressionFlow.utils import truncated_normal, standard_normal_logprob, standard_laplace_logprob\n",
    "\n",
    "# flow hypernetwork with kld loss\n",
    "def experiment_flow1(flow, opt,n):\n",
    "    support = torch.randn(5,65)\n",
    "    for i in range(n):\n",
    "        x = support\n",
    "        y = flow.sample_gaussian((*x.shape, flow.input_dim), None, flow.gpu)\n",
    "        opt.zero_grad()\n",
    "        batch_size = x.size(0)\n",
    "        x = flow.hyper(x)\n",
    "        target_networks_weights = flow.point_cnf(y, x, reverse=True).view(*y.size())\n",
    "\n",
    "        # Loss\n",
    "        _, delta_log_py = flow.point_cnf(target_networks_weights, x, torch.zeros(batch_size, y.size(1), 1).to(y))\n",
    "        log_py = standard_normal_logprob(y).view(batch_size, -1).sum(1, keepdim=True)\n",
    "        delta_log_py = delta_log_py.view(batch_size, y.size(1), 1).sum(1)\n",
    "        log_px = log_py - delta_log_py\n",
    "\n",
    "        # policzyc gestosci flowa log p_0(F^{-1}_\\theta(w_i) + J\n",
    "        loss = log_px.mean()\n",
    "\n",
    "        # policzyc gestosci priora log N(w_i | (0,I))\n",
    "        size_multivariate = target_networks_weights.flatten().size()[0]\n",
    "        multivariate_normal_distrib = torch.distributions.MultivariateNormal(\n",
    "                torch.zeros_like(target_networks_weights.flatten()).to(loss), torch.eye(size_multivariate).to(loss))\n",
    "        loss_density = multivariate_normal_distrib.log_prob(target_networks_weights.flatten())\n",
    "        loss = 0.01 * (loss - loss_density)\n",
    "\n",
    "        # loss = torch.norm(loss)\n",
    "\n",
    "        if i % 100 == 0 or i == n-1:\n",
    "            print(loss)\n",
    "            plotTheta(target_networks_weights,loss)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "\n",
    "experiment_flow1(flow,opt,2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "flow = HyperRegression(flow_args)\n",
    "opt = _get_opt_(list(flow.hyper.parameters()) + list(flow.point_cnf.parameters()))\n",
    "\n",
    "import torch\n",
    "from regressionFlow.utils import truncated_normal, standard_normal_logprob, standard_laplace_logprob\n",
    "\n",
    "# flow hypernetwork with norm loss\n",
    "def experiment_flow2(flow, opt,n):\n",
    "    support = torch.randn(5,65)\n",
    "    for i in range(n):\n",
    "        x = support\n",
    "        y = flow.sample_gaussian((*x.shape, flow.input_dim), None, flow.gpu)\n",
    "        opt.zero_grad()\n",
    "        x = flow.hyper(x)\n",
    "        target_networks_weights = flow.point_cnf(y, x, reverse=True).view(*y.size())\n",
    "\n",
    "        loss = torch.norm(torch.flatten(target_networks_weights))\n",
    "\n",
    "        if i % 100 == 0:\n",
    "            print(loss)\n",
    "            plotTheta(target_networks_weights,loss)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "\n",
    "experiment_flow2(flow,opt,2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter no. 0 mu=0.027014758437871933, std=1.049736499786377, loss=38.25019454956055\n",
      "iter no. 1 mu=0.07765619456768036, std=1.1228294372558594, loss=40.47907257080078\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [21], line 91\u001b[0m\n\u001b[1;32m     88\u001b[0m             opt\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     89\u001b[0m     forward_experiment()\n\u001b[0;32m---> 91\u001b[0m \u001b[43mexperiment_3\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn [21], line 89\u001b[0m, in \u001b[0;36mexperiment_3\u001b[0;34m(num_iter, do_norm_warmup)\u001b[0m\n\u001b[1;32m     87\u001b[0m         loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m     88\u001b[0m         opt\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m---> 89\u001b[0m \u001b[43mforward_experiment\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn [21], line 75\u001b[0m, in \u001b[0;36mexperiment_3.<locals>.forward_experiment\u001b[0;34m(norm_warmup)\u001b[0m\n\u001b[1;32m     73\u001b[0m     weights \u001b[38;5;241m=\u001b[39m get_sample_weights()\n\u001b[1;32m     74\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 75\u001b[0m     weights, loss \u001b[38;5;241m=\u001b[39m \u001b[43mget_sample_weights_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     77\u001b[0m target_network_weights \u001b[38;5;241m=\u001b[39m weights\n\u001b[1;32m     78\u001b[0m mean, std \u001b[38;5;241m=\u001b[39m get_weights_stats(target_network_weights)\n",
      "Cell \u001b[0;32mIn [21], line 43\u001b[0m, in \u001b[0;36mexperiment_3.<locals>.get_sample_weights_loss\u001b[0;34m(num_samples)\u001b[0m\n\u001b[1;32m     40\u001b[0m weights \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat((weights, target_networks_weights\u001b[38;5;241m.\u001b[39mflatten()))\n\u001b[1;32m     42\u001b[0m \u001b[38;5;66;03m# loss\u001b[39;00m\n\u001b[0;32m---> 43\u001b[0m _, delta_log_py \u001b[38;5;241m=\u001b[39m \u001b[43mflow\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpoint_cnf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtarget_networks_weights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzeros\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     44\u001b[0m log_py \u001b[38;5;241m=\u001b[39m standard_normal_logprob(y)\u001b[38;5;241m.\u001b[39mview(batch_size, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39msum(\u001b[38;5;241m1\u001b[39m, keepdim\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     45\u001b[0m delta_log_py \u001b[38;5;241m=\u001b[39m delta_log_py\u001b[38;5;241m.\u001b[39mview(batch_size, y\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m1\u001b[39m), \u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39msum(\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/fewshot/lib/python3.9/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Projects/Fewshot/few-shot-hypernets-public/regressionFlow/models/cnf.py:29\u001b[0m, in \u001b[0;36mSequentialFlow.forward\u001b[0;34m(self, x, context, logpx, reverse, inds, integration_times)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     28\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m inds:\n\u001b[0;32m---> 29\u001b[0m         x, logpx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchain\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogpx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mintegration_times\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreverse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     30\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x, logpx\n",
      "File \u001b[0;32m~/miniconda3/envs/fewshot/lib/python3.9/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Projects/Fewshot/few-shot-hypernets-public/regressionFlow/models/cnf.py:92\u001b[0m, in \u001b[0;36mCNF.forward\u001b[0;34m(self, x, context, logpx, integration_times, reverse)\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39modefunc\u001b[38;5;241m.\u001b[39mbefore_odeint()\n\u001b[1;32m     91\u001b[0m     \u001b[38;5;66;03m#print(self.sqrt_end_time)\u001b[39;00m\n\u001b[0;32m---> 92\u001b[0m     state_t \u001b[38;5;241m=\u001b[39m \u001b[43modeint\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     93\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43modefunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     94\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstates\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     95\u001b[0m \u001b[43m        \u001b[49m\u001b[43mintegration_times\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     96\u001b[0m \u001b[43m        \u001b[49m\u001b[43matol\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43matol\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     97\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrtol\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrtol\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     98\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msolver\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     99\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msolver_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    100\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    101\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    102\u001b[0m     \u001b[38;5;66;03m#self.odefunc.before_odeint(e=torch.ones(x.size()).requires_grad_(True).to(x))\u001b[39;00m\n\u001b[1;32m    103\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39modefunc\u001b[38;5;241m.\u001b[39mbefore_odeint()\n",
      "File \u001b[0;32m~/miniconda3/envs/fewshot/lib/python3.9/site-packages/torchdiffeq/_impl/adjoint.py:198\u001b[0m, in \u001b[0;36modeint_adjoint\u001b[0;34m(func, y0, t, rtol, atol, method, options, event_fn, adjoint_rtol, adjoint_atol, adjoint_method, adjoint_options, adjoint_params)\u001b[0m\n\u001b[1;32m    195\u001b[0m state_norm \u001b[38;5;241m=\u001b[39m options[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnorm\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    196\u001b[0m handle_adjoint_norm_(adjoint_options, shapes, state_norm)\n\u001b[0;32m--> 198\u001b[0m ans \u001b[38;5;241m=\u001b[39m \u001b[43mOdeintAdjointMethod\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mshapes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrtol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43matol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevent_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madjoint_rtol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madjoint_atol\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[43m                                \u001b[49m\u001b[43madjoint_method\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madjoint_options\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequires_grad\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43madjoint_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    201\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m event_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    202\u001b[0m     solution \u001b[38;5;241m=\u001b[39m ans\n",
      "File \u001b[0;32m~/miniconda3/envs/fewshot/lib/python3.9/site-packages/torchdiffeq/_impl/adjoint.py:25\u001b[0m, in \u001b[0;36mOdeintAdjointMethod.forward\u001b[0;34m(ctx, shapes, func, y0, t, rtol, atol, method, options, event_fn, adjoint_rtol, adjoint_atol, adjoint_method, adjoint_options, t_requires_grad, *adjoint_params)\u001b[0m\n\u001b[1;32m     22\u001b[0m ctx\u001b[38;5;241m.\u001b[39mevent_mode \u001b[38;5;241m=\u001b[39m event_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m---> 25\u001b[0m     ans \u001b[38;5;241m=\u001b[39m \u001b[43modeint\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrtol\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrtol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43matol\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43matol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevent_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mevent_fn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     27\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m event_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     28\u001b[0m         y \u001b[38;5;241m=\u001b[39m ans\n",
      "File \u001b[0;32m~/miniconda3/envs/fewshot/lib/python3.9/site-packages/torchdiffeq/_impl/odeint.py:77\u001b[0m, in \u001b[0;36modeint\u001b[0;34m(func, y0, t, rtol, atol, method, options, event_fn)\u001b[0m\n\u001b[1;32m     74\u001b[0m solver \u001b[38;5;241m=\u001b[39m SOLVERS[method](func\u001b[38;5;241m=\u001b[39mfunc, y0\u001b[38;5;241m=\u001b[39my0, rtol\u001b[38;5;241m=\u001b[39mrtol, atol\u001b[38;5;241m=\u001b[39matol, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions)\n\u001b[1;32m     76\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m event_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 77\u001b[0m     solution \u001b[38;5;241m=\u001b[39m \u001b[43msolver\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mintegrate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     79\u001b[0m     event_t, solution \u001b[38;5;241m=\u001b[39m solver\u001b[38;5;241m.\u001b[39mintegrate_until_event(t[\u001b[38;5;241m0\u001b[39m], event_fn)\n",
      "File \u001b[0;32m~/miniconda3/envs/fewshot/lib/python3.9/site-packages/torchdiffeq/_impl/solvers.py:30\u001b[0m, in \u001b[0;36mAdaptiveStepsizeODESolver.integrate\u001b[0;34m(self, t)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_before_integrate(t)\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mlen\u001b[39m(t)):\n\u001b[0;32m---> 30\u001b[0m     solution[i] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_advance\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m solution\n",
      "File \u001b[0;32m~/miniconda3/envs/fewshot/lib/python3.9/site-packages/torchdiffeq/_impl/rk_common.py:194\u001b[0m, in \u001b[0;36mRKAdaptiveStepsizeODESolver._advance\u001b[0;34m(self, next_t)\u001b[0m\n\u001b[1;32m    192\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m next_t \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrk_state\u001b[38;5;241m.\u001b[39mt1:\n\u001b[1;32m    193\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m n_steps \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_num_steps, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax_num_steps exceeded (\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m>=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(n_steps, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_num_steps)\n\u001b[0;32m--> 194\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrk_state \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_adaptive_step\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrk_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    195\u001b[0m     n_steps \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    196\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _interp_evaluate(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrk_state\u001b[38;5;241m.\u001b[39minterp_coeff, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrk_state\u001b[38;5;241m.\u001b[39mt0, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrk_state\u001b[38;5;241m.\u001b[39mt1, next_t)\n",
      "File \u001b[0;32m~/miniconda3/envs/fewshot/lib/python3.9/site-packages/torchdiffeq/_impl/rk_common.py:255\u001b[0m, in \u001b[0;36mRKAdaptiveStepsizeODESolver._adaptive_step\u001b[0;34m(self, rk_state)\u001b[0m\n\u001b[1;32m    250\u001b[0m         dt \u001b[38;5;241m=\u001b[39m t1 \u001b[38;5;241m-\u001b[39m t0\n\u001b[1;32m    252\u001b[0m \u001b[38;5;66;03m# Must be arranged as doing all the step_t handling, then all the jump_t handling, in case we\u001b[39;00m\n\u001b[1;32m    253\u001b[0m \u001b[38;5;66;03m# trigger both. (i.e. interleaving them would be wrong.)\u001b[39;00m\n\u001b[0;32m--> 255\u001b[0m y1, f1, y1_error, k \u001b[38;5;241m=\u001b[39m \u001b[43m_runge_kutta_step\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtableau\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtableau\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    256\u001b[0m \u001b[38;5;66;03m# dtypes:\u001b[39;00m\n\u001b[1;32m    257\u001b[0m \u001b[38;5;66;03m# y1.dtype == self.y0.dtype\u001b[39;00m\n\u001b[1;32m    258\u001b[0m \u001b[38;5;66;03m# f1.dtype == self.y0.dtype\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    263\u001b[0m \u001b[38;5;66;03m#                     Error Ratio                      #\u001b[39;00m\n\u001b[1;32m    264\u001b[0m \u001b[38;5;66;03m########################################################\u001b[39;00m\n\u001b[1;32m    265\u001b[0m error_ratio \u001b[38;5;241m=\u001b[39m _compute_error_ratio(y1_error, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrtol, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39matol, y0, y1, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm)\n",
      "File \u001b[0;32m~/miniconda3/envs/fewshot/lib/python3.9/site-packages/torchdiffeq/_impl/rk_common.py:76\u001b[0m, in \u001b[0;36m_runge_kutta_step\u001b[0;34m(func, y0, f0, t0, dt, t1, tableau)\u001b[0m\n\u001b[1;32m     74\u001b[0m         perturb \u001b[38;5;241m=\u001b[39m Perturb\u001b[38;5;241m.\u001b[39mNONE\n\u001b[1;32m     75\u001b[0m     yi \u001b[38;5;241m=\u001b[39m y0 \u001b[38;5;241m+\u001b[39m torch\u001b[38;5;241m.\u001b[39msum(k[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, :i \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m*\u001b[39m (beta_i \u001b[38;5;241m*\u001b[39m dt), dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mview_as(f0)\n\u001b[0;32m---> 76\u001b[0m     f \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mti\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43myi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mperturb\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mperturb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     77\u001b[0m     k \u001b[38;5;241m=\u001b[39m _UncheckedAssign\u001b[38;5;241m.\u001b[39mapply(k, f, (\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, i \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m     79\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (tableau\u001b[38;5;241m.\u001b[39mc_sol[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m (tableau\u001b[38;5;241m.\u001b[39mc_sol[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m tableau\u001b[38;5;241m.\u001b[39mbeta[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\u001b[38;5;241m.\u001b[39mall()):\n\u001b[1;32m     80\u001b[0m     \u001b[38;5;66;03m# This property (true for Dormand-Prince) lets us save a few FLOPs.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/fewshot/lib/python3.9/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/fewshot/lib/python3.9/site-packages/torchdiffeq/_impl/misc.py:189\u001b[0m, in \u001b[0;36m_PerturbFunc.forward\u001b[0;34m(self, t, y, perturb)\u001b[0m\n\u001b[1;32m    186\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    187\u001b[0m     \u001b[38;5;66;03m# Do nothing.\u001b[39;00m\n\u001b[1;32m    188\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m--> 189\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbase_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/fewshot/lib/python3.9/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/fewshot/lib/python3.9/site-packages/torchdiffeq/_impl/misc.py:189\u001b[0m, in \u001b[0;36m_PerturbFunc.forward\u001b[0;34m(self, t, y, perturb)\u001b[0m\n\u001b[1;32m    186\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    187\u001b[0m     \u001b[38;5;66;03m# Do nothing.\u001b[39;00m\n\u001b[1;32m    188\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m--> 189\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbase_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/fewshot/lib/python3.9/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/fewshot/lib/python3.9/site-packages/torchdiffeq/_impl/misc.py:138\u001b[0m, in \u001b[0;36m_TupleFunc.forward\u001b[0;34m(self, t, y)\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, t, y):\n\u001b[0;32m--> 138\u001b[0m     f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbase_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_flat_to_shape\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshapes\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    139\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcat([f_\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m f_ \u001b[38;5;129;01min\u001b[39;00m f])\n",
      "File \u001b[0;32m~/miniconda3/envs/fewshot/lib/python3.9/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Projects/Fewshot/few-shot-hypernets-public/regressionFlow/models/odefunc.py:176\u001b[0m, in \u001b[0;36mODEhyperfunc.forward\u001b[0;34m(self, t, states)\u001b[0m\n\u001b[1;32m    174\u001b[0m         divergence \u001b[38;5;241m=\u001b[39m divergence_approx(dy, y, e\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_e)\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    175\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 176\u001b[0m         divergence \u001b[38;5;241m=\u001b[39m \u001b[43mdivergence_bf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    177\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    178\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_div_approx_test:\n",
      "File \u001b[0;32m~/Projects/Fewshot/few-shot-hypernets-public/regressionFlow/models/odefunc.py:33\u001b[0m, in \u001b[0;36mdivergence_bf\u001b[0;34m(dx, y)\u001b[0m\n\u001b[1;32m     31\u001b[0m sum_diag \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.\u001b[39m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(y\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]):\n\u001b[0;32m---> 33\u001b[0m     sum_diag \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgrad\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdx\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msum\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mcontiguous()[:, :, i]\u001b[38;5;241m.\u001b[39mcontiguous()\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m sum_diag\u001b[38;5;241m.\u001b[39mcontiguous()\n",
      "File \u001b[0;32m~/miniconda3/envs/fewshot/lib/python3.9/site-packages/torch/autograd/__init__.py:276\u001b[0m, in \u001b[0;36mgrad\u001b[0;34m(outputs, inputs, grad_outputs, retain_graph, create_graph, only_inputs, allow_unused, is_grads_batched)\u001b[0m\n\u001b[1;32m    274\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _vmap_internals\u001b[38;5;241m.\u001b[39m_vmap(vjp, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, allow_none_pass_through\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)(grad_outputs_)\n\u001b[1;32m    275\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 276\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    277\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_outputs_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    278\u001b[0m \u001b[43m        \u001b[49m\u001b[43mallow_unused\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "flow = HyperRegression(flow_args)\n",
    "opt = _get_opt_(list(flow.hyper.parameters()) + list(flow.point_cnf.parameters()))\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from regressionFlow.utils import truncated_normal, standard_normal_logprob, standard_laplace_logprob\n",
    "import numpy as np\n",
    "\n",
    "def plotHist(X, n = 10):\n",
    "  x = X.cpu().detach().numpy()[:n]\n",
    "  plt.hist(x, bins = 25)\n",
    "  plt.show()\n",
    "\n",
    "\n",
    "def experiment_3(num_iter=1000,do_norm_warmup=False):\n",
    "    \"\"\"\n",
    "    FLOW zwraca kilka zestawow wag do klasyfikatora. Liczymy statystyki na skonkatenowanych zestawach wag, ktore raportujemy\n",
    "    z kazda iteracja. Funkcja kosztu moze byc z warmupem normowym.\n",
    "    \"\"\"\n",
    "    support = torch.randn(5,65)\n",
    "    batch_size = support.size(0)\n",
    "    \n",
    "    def get_sample_weights(num_samples=10) -> list[torch.tensor]:\n",
    "        \"\"\"zwraca kilka zestawow wag z flowa\"\"\"\n",
    "        weights = torch.empty(0).to('cuda')\n",
    "        for _ in range(num_samples):\n",
    "            y = flow.sample_gaussian((*support.shape, flow.input_dim), None, flow.gpu)\n",
    "            x = flow.hyper(support)\n",
    "            target_networks_weights = flow.point_cnf(y, x, reverse=True).view(*y.size())\n",
    "            weights = torch.cat((weights, target_networks_weights.flatten()))\n",
    "        return weights\n",
    "\n",
    "    def get_sample_weights_loss(num_samples=10) -> (list[torch.tensor],list[torch.tensor]):\n",
    "        \"\"\"zwraca kilka zestawow wag z flowa i ich lossy\"\"\"\n",
    "        weights = torch.empty(0).to('cuda')\n",
    "        _loss = None\n",
    "        for _ in range(num_samples):\n",
    "            y = flow.sample_gaussian((*support.shape, flow.input_dim), None, flow.gpu)\n",
    "            x = flow.hyper(support)\n",
    "            target_networks_weights = flow.point_cnf(y, x, reverse=True).view(*y.size())\n",
    "            weights = torch.cat((weights, target_networks_weights.flatten()))\n",
    "\n",
    "            # loss\n",
    "            _, delta_log_py = flow.point_cnf(target_networks_weights, x, torch.zeros(batch_size, y.size(1), 1).to(y))\n",
    "            log_py = standard_normal_logprob(y).view(batch_size, -1).sum(1, keepdim=True)\n",
    "            delta_log_py = delta_log_py.view(batch_size, y.size(1), 1).sum(1)\n",
    "            log_px = log_py - delta_log_py\n",
    "            # policzyc gestosci flowa log p_0(F^{-1}_\\theta(w_i) + J\n",
    "            loss = log_px.mean()\n",
    "            # policzyc gestosci priora log N(w_i | (0,I))\n",
    "            size_multivariate = target_networks_weights.flatten().size()[0]\n",
    "            multivariate_normal_distrib = torch.distributions.MultivariateNormal(\n",
    "                    torch.zeros_like(target_networks_weights.flatten()).to(loss), torch.eye(size_multivariate).to(loss))\n",
    "            loss_density = multivariate_normal_distrib.log_prob(target_networks_weights.flatten())\n",
    "            loss = 0.01 * (loss - loss_density)\n",
    "            if _loss is None:\n",
    "                _loss = loss\n",
    "            else:\n",
    "                _loss = _loss + loss\n",
    "\n",
    "        return weights, torch.mean(_loss)\n",
    "\n",
    "    def get_weights_stats(weights_samples) -> (float,float):\n",
    "        \"\"\"zwraca srednia i std z probki wag flowa do klasyfikatora\"\"\"\n",
    "        mean = torch.mean(weights_samples)\n",
    "        std = torch.std(weights_samples)\n",
    "        return mean,std\n",
    "\n",
    "    def forward_experiment(norm_warmup=10):\n",
    "        for i in range(num_iter):\n",
    "            opt.zero_grad()\n",
    "\n",
    "            if i <= norm_warmup and do_norm_warmup:\n",
    "                weights = get_sample_weights()\n",
    "            else:\n",
    "                weights, loss = get_sample_weights_loss()\n",
    "            \n",
    "            target_network_weights = weights\n",
    "            mean, std = get_weights_stats(target_network_weights)\n",
    "\n",
    "            if i <= norm_warmup and do_norm_warmup:\n",
    "                loss = torch.norm(torch.flatten(target_network_weights))\n",
    "\n",
    "            if i % 100 == 0:\n",
    "                plotTheta(target_network_weights[:325],loss)\n",
    "                plotHist(target_network_weights)\n",
    "            print(f\"iter no. {i} mu={mean}, std={std}, loss={loss}\")\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "    forward_experiment()\n",
    "\n",
    "experiment_3()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
